{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models_and_tools.ACGAN_paper import *\n",
    "from models_and_tools.ACGAN_simple import *\n",
    "from models_and_tools.functions import *\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downloading the model and parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (main): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Dropout(p=0.5, inplace=False)\n    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n    (10): Dropout(p=0.5, inplace=False)\n    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n    (14): Dropout(p=0.5, inplace=False)\n    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): LeakyReLU(negative_slope=0.2, inplace=True)\n    (18): Dropout(p=0.5, inplace=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (21): LeakyReLU(negative_slope=0.2, inplace=True)\n    (22): Dropout(p=0.5, inplace=False)\n  )\n  (classification): Sequential(\n    (0): Linear(in_features=8192, out_features=11, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(conf).to(device)\n",
    "netD = Discriminator(conf).to(device)\n",
    "# Load the weights back into the models\n",
    "netG.load_state_dict(torch.load('netG200.pth'))\n",
    "netD.load_state_dict(torch.load('netD200.pth'))\n",
    "# Make sure to call eval() if you're in inference mode\n",
    "netG.eval()\n",
    "netD.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining functions required for the SSIM score calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def rgb_to_grayscale_numpy(image):\n",
    "\t\"\"\"\n",
    "\tConvert an RGB image to a grayscale image using the luminosity method.\n",
    "\tParameters:\n",
    "\t\timage (numpy.ndarray): The RGB image in CHW format.\n",
    "\tReturns:\n",
    "\t\tnumpy.ndarray: The grayscale image in 1HW format (1 channel, Height, Width).\n",
    "\t\"\"\"\n",
    "\tif image.shape[0] == 3:  # Check if the input image has 3 channels (RGB)\n",
    "\t\timage = image.transpose(1, 2, 0)  # Convert to HWC format for easier processing\n",
    "\t# Apply the luminosity method to calculate grayscale values\n",
    "\tgrayscale = 0.2989 * image[:, :, 0] + 0.5870 * image[:, :, 1] + 0.1140 * image[:, :, 2]\n",
    "\treturn grayscale[np.newaxis, :, :]  # Add channel dimension back for consistency\n",
    "\n",
    "\n",
    "def calculate_ssim(image1, image2):\n",
    "\t\"\"\"\n",
    "    Calculate the Structural Similarity Index Measure (SSIM) between two images.\n",
    "    Parameters:\n",
    "        image1, image2 (numpy.ndarray or torch.Tensor): The input images.\n",
    "    Returns:\n",
    "        float: The SSIM index between the two input images.\n",
    "    \"\"\"\n",
    "\t# Convert PyTorch tensors to numpy arrays if necessary\n",
    "\tif torch.is_tensor(image1):\n",
    "\t\timage1 = image1.cpu().numpy()  # CHW to HWC\n",
    "\tif torch.is_tensor(image2):\n",
    "\t\timage2 = image2.cpu().numpy()  # CHW to HWC\n",
    "\t# Convert images to grayscale\n",
    "\timage1 = rgb_to_grayscale_numpy(image1)[0]\n",
    "\timage2 = rgb_to_grayscale_numpy(image2)[0]\n",
    "\t# Normalize images to ensure they are compared on the same scale\n",
    "\timage1 = (image1 - image1.min()) / (image1.max() - image1.min())\n",
    "\timage2 = (image2 - image2.min()) / (image2.max() - image2.min())\n",
    "\t# Calculate and return the SSIM\n",
    "\tssim_value = ssim(image1, image2, multichannel=False, data_range=1)\n",
    "\treturn ssim_value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we need to generate 2 times 1000 images using our GAN model named fake_images1 and fake_images2. For AC-GAN it's a little bit different compared to  normal GANS."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_images_acc = 1000  # number of images\n",
    "noise = torch.randn(num_images_acc, 100, device=device)  #noise for images\n",
    "# creating labels (required only for AC-GAM)\n",
    "fake_labels = torch.randint(0, conf.num_classes, (num_images_acc,), device=device)\n",
    "fake_labels_oh = torch.nn.functional.one_hot(fake_labels, num_classes=10)  # one-hot representation\n",
    "# generating images - 1st pack\n",
    "fake_images = netG(noise, fake_labels_oh).detach()\n",
    "# Now repeating the same procedure for the 2nd pack of the images\n",
    "noise2 = torch.randn(num_images_acc, 100, device=device)\n",
    "fake_labels2 = fake_labels\n",
    "fake_labels_oh2 = torch.nn.functional.one_hot(fake_labels, num_classes=10)\n",
    "# generating images - 1st pack\n",
    "fake_images2 = netG(noise2, fake_labels_oh2).detach()\n",
    "# Calculate SSIM for each pair\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating the average SSIM score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM (AC-GAN): 0.08215493456964973\n"
     ]
    }
   ],
   "source": [
    "ssim_scores = []\n",
    "for gen_img, gen_img2 in zip(fake_images, fake_images2):  # 2 packs pairwise\n",
    "\tcurrent_ssim = calculate_ssim(gen_img, gen_img2)\n",
    "\tssim_scores.append(current_ssim)\n",
    "\n",
    "average_ssim_ACGAN = np.mean(ssim_scores)\n",
    "print(f\"Average SSIM (AC-GAN): {average_ssim_ACGAN}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This number will be placed in 1 plot, comparing all the models"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
